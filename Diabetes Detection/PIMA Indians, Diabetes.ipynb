{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIMA Indians, Diabetes\n",
    "PIMA Indians [dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database) obtained from the UCI Machine Learning Repository. The goal is to predict whether or not a given female patient will contract diabetes based on features such as BMI, age, and number of pregnancies. Therefore, it is a binary classification problem. A target value of 0 indicates that the patient does not have diabetes, while a value of 1 indicates that the patient does have diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "0            6      148         72       35        0  33.6  0.627   50   \n",
       "1            1       85         66       29        0  26.6  0.351   31   \n",
       "2            8      183         64        0        0  23.3  0.672   32   \n",
       "3            1       89         66       23       94  28.1  0.167   21   \n",
       "4            0      137         40       35      168  43.1  2.288   33   \n",
       "\n",
       "   diabetes  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the last column for \"diabetes\" is a classification of 1 or 0 meaning whether or not the patient has the disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pregnancies     glucose   diastolic     triceps     insulin  \\\n",
       "count   768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean      3.845052  120.894531   69.105469   20.536458   79.799479   \n",
       "std       3.369578   31.972618   19.355807   15.952218  115.244002   \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%       1.000000   99.000000   62.000000    0.000000    0.000000   \n",
       "50%       3.000000  117.000000   72.000000   23.000000   30.500000   \n",
       "75%       6.000000  140.250000   80.000000   32.000000  127.250000   \n",
       "max      17.000000  199.000000  122.000000   99.000000  846.000000   \n",
       "\n",
       "              bmi         dpf         age    diabetes  \n",
       "count  768.000000  768.000000  768.000000  768.000000  \n",
       "mean    31.992578    0.471876   33.240885    0.348958  \n",
       "std      7.884160    0.331329   11.760232    0.476951  \n",
       "min      0.000000    0.078000   21.000000    0.000000  \n",
       "25%     27.300000    0.243750   24.000000    0.000000  \n",
       "50%     32.000000    0.372500   29.000000    0.000000  \n",
       "75%     36.600000    0.626250   41.000000    1.000000  \n",
       "max     67.100000    2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "pregnancies    768 non-null int64\n",
      "glucose        768 non-null int64\n",
      "diastolic      768 non-null int64\n",
      "triceps        768 non-null int64\n",
      "insulin        768 non-null int64\n",
      "bmi            768 non-null float64\n",
      "dpf            768 non-null float64\n",
      "age            768 non-null int64\n",
      "diabetes       768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n",
      "(768, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create arrays for features and target variable\n",
    "y = df['diabetes'].values\n",
    "X = df.drop('diabetes', axis=1).values\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176  30]\n",
      " [ 56  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       206\n",
      "           1       0.61      0.45      0.52       102\n",
      "\n",
      "    accuracy                           0.72       308\n",
      "   macro avg       0.68      0.65      0.66       308\n",
      "weighted avg       0.71      0.72      0.71       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)\n",
    "\n",
    "# Instantiate a k-NN classifier: knn\n",
    "knn = KNeighborsClassifier(n_neighbors= 6)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple terms, high precision means that an algorithm returned substantially more relevant results than irrelevant ones, while high recall means that an algorithm returned most of the relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[170  36]\n",
      " [ 36  66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       206\n",
      "           1       0.65      0.65      0.65       102\n",
      "\n",
      "    accuracy                           0.77       308\n",
      "   macro avg       0.74      0.74      0.74       308\n",
      "weighted avg       0.77      0.77      0.77       308\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at our classification and logistic model, the logistic model had a overall better numbers in comparison to the confusion matrices.\n",
    "\n",
    "# ROC Curve\n",
    "ROC curve provides a nice visual way to assess your classifier's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at your ROC curve, you may have noticed that the y-axis (True positive rate) is also known as recall. Indeed, in addition to the ROC curve, there are other ways to visually evaluate model performance. One such way is the precision-recall curve, which is generated by plotting the precision and recall for different thresholds.\n",
    "\n",
    "Formulas:\n",
    "- Precision= TP / (TP+FP)\n",
    "- Recall=TP / (TP+FN)\n",
    "\n",
    "True negatives do not appear at all in the definitions of precision and recall.\n",
    "\n",
    "The more area under the ROC curve means a better model.\n",
    "\n",
    "# AUC computation\n",
    "If a binary classifier that in fact is just randomly making guesses. It would be correct approximately 50% of the time, and the resulting ROC curve would be a diagonal line in which the True Positive Rate and False Positive Rate are always equal. The Area under this ROC curve would be 0.5. This is one way in which the AUC, is an informative metric to evaluate a model. If the AUC is greater than 0.5, the model is better than random guessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Using the logreg classifier, which has been fit to the training data, compute the predicted probabilities of the labels of the test set X_test\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute cross-validated AUC scores: 5-fold cross-validation\n",
    "cv_auc = cross_val_score(logreg, X, y, cv = 5, scoring =\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8260517799352751\n"
     ]
    }
   ],
   "source": [
    "# Compute the AUC score to the test set labels y_test, and the predicted probabilities \n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC scores computed using 5-fold cross-validation: [0.80814815 0.80796296 0.82666667 0.87471698 0.83339623]\n"
     ]
    }
   ],
   "source": [
    "#Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC represents the probability that a random positive is positioned to the right of a random negative. AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0. Sp we cam see that our model is performing relative well at 0.83.\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "A tuning parameter is introduced called simply C that defines the magnitude of the wiggle allowed across all dimensions. The C parameters defines the amount of violation of the margin allowed. A C=0 is no violation and we are back to the inflexible Maximal-Margin Classifier described above. The larger the value of C the more violations of the hyperplane are permitted.\n",
    "\n",
    "During the learning of the hyperplane from data, all training instances that lie within the distance of the margin will affect the placement of the hyperplane and are referred to as support vectors. And as C affects the number of instances that are allowed to fall within the margin, C influences the number of support vectors used by the model.\n",
    "\n",
    "- The smaller the value of C, the more sensitive the algorithm is to the training data (higher variance and lower bias).\n",
    "- The larger the value of C, the less sensitive the algorithm is to the training data (lower variance and higher bias).\n",
    "\n",
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {\"C\": c_space, \"penalty\": ['l1', 'l2']}\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.40, random_state = 42)\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv = 5)\n",
    "\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 163789.3706954068, 'penalty': 'l2'}\n",
      "Tuned Logistic Regression Accuracy: 0.7782608695652173\n"
     ]
    }
   ],
   "source": [
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a 'C' of 31.622 results in the best performance.\n",
    "\n",
    "## RandomizedSearchCV\n",
    "GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space and dealing with multiple hyperparameters. A solution to this is to use RandomizedSearchCV, in which not all hyperparameter values are tried out. Instead, a fixed number of hyperparameter settings is sampled from specified probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'gini', 'max_depth': None, 'max_features': 4, 'min_samples_leaf': 2}\n",
      "Best score: 0.7217391304347827\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score: {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that RandomizedSearchCV will never outperform GridSearchCV. Instead, it is valuable because it saves on computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
